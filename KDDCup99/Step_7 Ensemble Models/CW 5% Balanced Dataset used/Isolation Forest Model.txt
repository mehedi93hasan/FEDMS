import pandas as pd
import pickle
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import numpy as np

# Load data
df = pd.read_csv('CW_5percent_kddcup99_minmax.csv')
X = df.drop('label', axis=1) if 'label' in df.columns else df  # Remove target if exists
y = df['label'] if 'label' in df.columns else None

# Scale features (recommended for Isolation Forest)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data if you have labels for evaluation
if y is not None:
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )
else:
    X_train = X_scaled

# Train Isolation Forest model
iso_forest = IsolationForest(
    n_estimators=100,
    contamination=0.1,  # Expected proportion of outliers
    random_state=42,
    n_jobs=-1
)

iso_forest.fit(X_train)

# Predict anomalies (-1 for outliers, 1 for inliers)
anomaly_scores = iso_forest.decision_function(X_train)
predictions = iso_forest.predict(X_train)

print(f"Number of outliers detected: {np.sum(predictions == -1)}")
print(f"Percentage of outliers: {(np.sum(predictions == -1) / len(predictions)) * 100:.2f}%")

# Save model and preprocessing objects
model_data = {
    'model': iso_forest,
    'scaler': scaler,
    'feature_names': X.columns.tolist()
}

with open('CW_5percent_isolation_forest_model_kddcup.pkl', 'wb') as f:
    pickle.dump(model_data, f)

print("Model saved as CW_5percent_isolation_forest_model_kddcup.pkl")