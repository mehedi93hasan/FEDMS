import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical
import os
import warnings
warnings.filterwarnings('ignore')

class CWAttacker:
    def __init__(self, model, num_classes):
        self.model = model
        self.num_classes = num_classes

    def cw_l2_attack(self, x_samples, y_true, c=1.0, kappa=0, max_iterations=1000, learning_rate=0.01):
        """Generate C&W L2 adversarial examples"""
        batch_size = x_samples.shape[0]

        # Convert to tensorflow variables
        x_original = tf.constant(x_samples.astype(np.float32))
        y_target = tf.constant(y_true.astype(np.float32))

        # Initialize perturbation variable (w in the paper)
        w = tf.Variable(tf.zeros_like(x_original), trainable=True)

        # Optimizer
        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)

        best_perturbations = np.zeros_like(x_samples)
        best_distances = np.full(batch_size, np.inf)

        for iteration in range(max_iterations):
            with tf.GradientTape() as tape:
                # Generate adversarial examples
                x_adv = x_original + w

                # Get model predictions
                logits = self.model(x_adv)

                # Calculate loss components
                # L2 distance loss
                l2_loss = tf.reduce_sum(tf.square(w), axis=1)

                # Classification loss (C&W objective)
                real = tf.reduce_sum(y_target * logits, axis=1)
                other = tf.reduce_max((1 - y_target) * logits - y_target * 10000, axis=1)
                loss1 = tf.maximum(0.0, other - real + kappa)

                # Total loss
                loss = l2_loss + c * loss1
                total_loss = tf.reduce_mean(loss)

            # Calculate gradients and apply
            gradients = tape.gradient(total_loss, w)
            optimizer.apply_gradients([(gradients, w)])

            # Update best perturbations
            if iteration % 100 == 0:
                current_distances = tf.reduce_sum(tf.square(w), axis=1).numpy()
                current_predictions = tf.argmax(logits, axis=1).numpy()
                true_labels = tf.argmax(y_target, axis=1).numpy()

                # Check for successful attacks with smaller perturbations
                for i in range(batch_size):
                    if (current_predictions[i] != true_labels[i] and
                        current_distances[i] < best_distances[i]):
                        best_distances[i] = current_distances[i]
                        best_perturbations[i] = w[i].numpy()

        # Generate final adversarial examples
        x_adversarial = x_samples + best_perturbations

        return x_adversarial, best_perturbations

    def generate_cw_batch(self, x_samples, y_true, c_values=[0.1, 1.0, 10.0]):
        """Generate C&W attacks with different c values to find optimal perturbations"""
        best_x_adv = x_samples.copy()
        best_perturbations = np.zeros_like(x_samples)
        best_distances = np.full(len(x_samples), np.inf)

        for c in c_values:
            print(f"     Trying c={c}")
            try:
                x_adv, perturbations = self.cw_l2_attack(x_samples, y_true, c=c, max_iterations=500)

                # Check which samples improved
                distances = np.linalg.norm(perturbations, axis=1)
                predictions = self.model.predict(x_adv, verbose=0)
                pred_classes = np.argmax(predictions, axis=1)
                true_classes = np.argmax(y_true, axis=1)

                # Update best results for successful attacks
                for i in range(len(x_samples)):
                    if (pred_classes[i] != true_classes[i] and distances[i] < best_distances[i]):
                        best_distances[i] = distances[i]
                        best_x_adv[i] = x_adv[i]
                        best_perturbations[i] = perturbations[i]

            except Exception as e:
                print(f"     Error with c={c}: {str(e)[:50]}")
                continue

        return best_x_adv, best_perturbations

def create_and_train_model(X_train, y_train, X_test, y_test):
    """Create and train a neural network"""
    model = Sequential([
        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
        Dropout(0.3),
        Dense(32, activation='relu'),
        Dropout(0.3),
        Dense(y_train.shape[1], activation='softmax')
    ])

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, verbose=0)

    _, accuracy = model.evaluate(X_test, y_test, verbose=0)
    print(f"‚úì Model trained with accuracy: {accuracy:.4f}")

    return model

def generate_cw_attacks_and_csv(csv_path, epsilon_percentages=[2, 5, 10, 20], sample_size=500000):
    """Complete C&W attack pipeline"""
    print("üéØ Starting C&W Attack Generation")

    # Load and prepare data
    data = pd.read_csv(csv_path)
    print(f"‚úì Loaded dataset: {data.shape}")

    # Separate features and labels
    if 'label' in data.columns:
        X = data.drop('label', axis=1).values
        y = data['label'].values
        feature_names = list(data.columns[:-1])
    else:
        X = data.iloc[:, :-1].values
        y = data.iloc[:, -1].values
        feature_names = [f'feature_{i}' for i in range(X.shape[1])]

    # Encode labels
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    y_categorical = to_categorical(y_encoded)
    num_classes = y_categorical.shape[1]

    # Split and scale data
    X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Train model
    model = create_and_train_model(X_train_scaled, y_train, X_test_scaled, y_test)

    # Initialize C&W attacker
    attacker = CWAttacker(model, num_classes)

    # Select samples for attack (smaller sample size due to computational cost)
    if sample_size > len(X_test_scaled):
        sample_size = len(X_test_scaled)

    indices = np.random.choice(len(X_test_scaled), sample_size, replace=False)
    X_attack = X_test_scaled[indices]
    y_attack = y_test[indices]
    y_labels = label_encoder.inverse_transform(np.argmax(y_attack, axis=1))

    # Calculate data range for epsilon bounds
    data_range = np.max(X_attack) - np.min(X_attack)

    # Create output directory
    output_dir = 'adversarial_csv_cw'
    os.makedirs(output_dir, exist_ok=True)

    print(f"‚úì Generating C&W attacks for {len(epsilon_percentages)} perturbation levels...")
    print(f"‚úì Using {sample_size} samples (C&W is computationally intensive)")

    summary_data = []

    # Generate attacks for each epsilon (used as constraint, not direct parameter)
    for eps_percent in epsilon_percentages:
        epsilon_bound = (eps_percent / 100.0) * data_range
        print(f"\nüî∏ {eps_percent}% perturbation constraint (Œµ‚â§{epsilon_bound:.6f})")

        # Process in smaller batches due to memory constraints
        batch_size = 50
        all_x_adv = []
        all_perturbations = []

        for i in range(0, len(X_attack), batch_size):
            batch_end = min(i + batch_size, len(X_attack))
            X_batch = X_attack[i:batch_end]
            y_batch = y_attack[i:batch_end]

            print(f"   Processing batch {i//batch_size + 1}/{(len(X_attack)-1)//batch_size + 1}")

            # Generate C&W attacks for this batch
            x_adv_batch, perturbations_batch = attacker.generate_cw_batch(X_batch, y_batch)

            # Apply epsilon constraint (clip perturbations if they exceed bound)
            perturbation_norms = np.linalg.norm(perturbations_batch, axis=1, keepdims=True)
            scale_factors = np.minimum(1.0, epsilon_bound / (perturbation_norms + 1e-8))
            perturbations_batch = perturbations_batch * scale_factors
            x_adv_batch = X_batch + perturbations_batch

            all_x_adv.append(x_adv_batch)
            all_perturbations.append(perturbations_batch)

        # Combine all batches
        x_adv = np.vstack(all_x_adv)
        perturbations = np.vstack(all_perturbations)

        # Calculate statistics
        predictions_clean = model.predict(X_attack, verbose=0)
        predictions_adv = model.predict(x_adv, verbose=0)

        accuracy_clean = accuracy_score(np.argmax(y_attack, axis=1), np.argmax(predictions_clean, axis=1))
        accuracy_adv = accuracy_score(np.argmax(y_attack, axis=1), np.argmax(predictions_adv, axis=1))
        attack_success_rate = 1 - accuracy_adv

        # Calculate perturbation statistics
        perturbation_norms = np.linalg.norm(perturbations, axis=1)
        avg_perturbation_norm = np.mean(perturbation_norms)

        print(f"   ‚úì Attack success rate: {attack_success_rate:.4f}")
        print(f"   ‚úì Avg perturbation norm: {avg_perturbation_norm:.6f}")

        # Create CSV
        df_adversarial = pd.DataFrame(x_adv, columns=feature_names)
        df_adversarial['label'] = y_labels
        df_adversarial['perturbation_level'] = f'{eps_percent}%'
        df_adversarial['epsilon_bound'] = epsilon_bound
        df_adversarial['attack_method'] = 'C&W'
        df_adversarial['optimization_type'] = 'L2'
        df_adversarial['perturbation_norm'] = perturbation_norms

        # Add predictions
        predicted_classes = np.argmax(predictions_adv, axis=1)
        predicted_labels = label_encoder.inverse_transform(predicted_classes)
        df_adversarial['predicted_label'] = predicted_labels
        df_adversarial['prediction_confidence'] = np.max(predictions_adv, axis=1)
        df_adversarial['attack_successful'] = (y_labels != predicted_labels)

        # Calculate optimization quality (lower L2 norm is better for C&W)
        df_adversarial['optimization_quality'] = 1.0 / (df_adversarial['perturbation_norm'] + 1e-8)

        # Save CSV
        csv_filename = f"{output_dir}/cw_adversarial_examples_{eps_percent}percent.csv"
        df_adversarial.to_csv(csv_filename, index=False)
        print(f"   ‚úì Saved: {csv_filename}")

        # Store summary
        summary_data.append({
            'perturbation_level': f'{eps_percent}%',
            'epsilon_bound': epsilon_bound,
            'samples_count': len(x_adv),
            'attack_success_rate': attack_success_rate,
            'avg_perturbation_norm': avg_perturbation_norm,
            'min_perturbation_norm': np.min(perturbation_norms),
            'max_perturbation_norm': np.max(perturbation_norms),
            'attack_method': 'C&W'
        })

    # Save summary
    summary_df = pd.DataFrame(summary_data)
    summary_path = f"{output_dir}/cw_attack_summary.csv"
    summary_df.to_csv(summary_path, index=False)

    print(f"\n‚úÖ C&W Attack Generation Completed!")
    print(f"üìÑ Files created:")
    for eps in epsilon_percentages:
        print(f"   ‚Ä¢ {output_dir}/cw_adversarial_examples_{eps}percent.csv")
    print(f"   ‚Ä¢ {output_dir}/cw_attack_summary.csv")

    print(f"\nüìä Summary:")
    print(summary_df.to_string(index=False))

    return summary_df

def compare_attack_methods():
    """Compare C&W with other attack methods"""
    print("\nüîç COMPARING C&W WITH OTHER ATTACKS")
    print("=" * 50)

    attack_dirs = {
        'C&W': 'adversarial_csv_cw',
        'PGD': 'adversarial_csv_pgd',
        'BIM': 'adversarial_csv_bim',
        'DeepFool': 'adversarial_csv_deepfool',
        'FGSM': 'adversarial_csv'
    }

    comparison_data = []

    for method, directory in attack_dirs.items():
        if method == 'FGSM':
            summary_file = f"{directory}/attack_summary.csv"
        else:
            summary_file = f"{directory}/{method.lower()}_attack_summary.csv"

        try:
            summary = pd.read_csv(summary_file)

            for _, row in summary.iterrows():
                comparison_data.append({
                    'Method': method,
                    'Perturbation': row['perturbation_level'],
                    'Success Rate': f"{row['attack_success_rate']:.4f}",
                    'Avg Norm': f"{row['avg_perturbation_norm']:.6f}"
                })
        except FileNotFoundError:
            print(f"‚ö†Ô∏è  {method} results not found")

    if comparison_data:
        comparison_df = pd.DataFrame(comparison_data)

        # Pivot table for better comparison
        pivot_success = comparison_df.pivot(index='Perturbation', columns='Method', values='Success Rate')
        pivot_norm = comparison_df.pivot(index='Perturbation', columns='Method', values='Avg Norm')

        print("\nüìä Attack Success Rate Comparison:")
        print(pivot_success.to_string())

        print("\nüìè Average Perturbation Norm Comparison:")
        print(pivot_norm.to_string())

        print(f"\nüí° C&W Characteristics:")
        print(f"   ‚Ä¢ Optimization-based attack (not gradient-based)")
        print(f"   ‚Ä¢ Often finds smaller perturbations than gradient methods")
        print(f"   ‚Ä¢ More computationally expensive but higher quality")
        print(f"   ‚Ä¢ Considered one of the strongest attacks available")

# Example usage
if __name__ == "__main__":
    # üîπ UPDATE THIS PATH
    CSV_PATH = "kdd_selected_features.csv"

    print("üßÆ C&W ATTACK IMPLEMENTATION")
    print("=" * 50)

    try:
        # Generate C&W attacks and CSV files
        summary = generate_cw_attacks_and_csv(CSV_PATH, sample_size=200)  # Smaller sample due to computational cost

        print(f"\nüéØ Ready for defense testing!")
        print(f"C&W characteristics:")
        print(f"   ‚Ä¢ Optimization-based (not gradient-based)")
        print(f"   ‚Ä¢ Finds minimal L2 perturbations")
        print(f"   ‚Ä¢ High-quality adversarial examples")
        print(f"   ‚Ä¢ Computationally intensive but very effective")

        print(f"\nLoad adversarial examples:")
        print(f"   df = pd.read_csv('adversarial_csv_cw/cw_adversarial_examples_10percent.csv')")
        print(f"   X_adv = df[feature_columns].values")
        print(f"   y_true = df['label'].values")

        # Compare with other methods if available
        compare_attack_methods()

    except FileNotFoundError:
        print(f"‚ùå Dataset not found at: {CSV_PATH}")
        print(f"Please update CSV_PATH with your actual file location")
    except Exception as e:
        print(f"‚ùå Error: {e}")
        print(f"Note: C&W is computationally intensive and may take longer than other attacks")
