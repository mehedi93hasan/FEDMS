"""
Concise PGD Attack Implementation for KDD Cup Dataset
Generates 4 CSV files with 2%, 5%, 10%, 20% perturbations
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical
import os
import warnings
warnings.filterwarnings('ignore')

class PGDAttacker:
    def __init__(self, model):
        self.model = model

    def pgd_attack(self, x_samples, y_true, epsilon, alpha=None, num_iterations=40, random_start=True):
        """Generate PGD adversarial examples"""
        if alpha is None:
            alpha = epsilon / 4  # Common PGD setting

        x_original = tf.constant(x_samples.astype(np.float32))

        # Random initialization within epsilon ball
        if random_start:
            x_adversarial = x_original + tf.random.uniform(x_original.shape, -epsilon, epsilon)
            # Project to epsilon ball
            x_adversarial = tf.clip_by_value(x_adversarial, x_original - epsilon, x_original + epsilon)
        else:
            x_adversarial = tf.Variable(x_original)

        for iteration in range(num_iterations):
            x_adversarial = tf.Variable(x_adversarial)

            with tf.GradientTape() as tape:
                tape.watch(x_adversarial)
                predictions = self.model(x_adversarial)
                loss = tf.keras.losses.categorical_crossentropy(y_true, predictions)

            # Calculate gradients
            gradients = tape.gradient(loss, x_adversarial)

            # Apply gradient step
            signed_gradients = tf.sign(gradients)
            x_adversarial = x_adversarial + alpha * signed_gradients

            # Project back to epsilon ball around original samples
            x_adversarial = tf.clip_by_value(x_adversarial, x_original - epsilon, x_original + epsilon)

        return x_adversarial.numpy(), (x_adversarial - x_original).numpy()

def create_and_train_model(X_train, y_train, X_test, y_test):
    """Create and train a neural network"""
    model = Sequential([
        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
        Dropout(0.3),
        Dense(32, activation='relu'),
        Dropout(0.3),
        Dense(y_train.shape[1], activation='softmax')
    ])

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, verbose=0)

    _, accuracy = model.evaluate(X_test, y_test, verbose=0)
    print(f"‚úì Model trained with accuracy: {accuracy:.4f}")

    return model

def generate_pgd_attacks_and_csv(csv_path, epsilon_percentages=[2, 5, 10, 20], sample_size=500000, num_iterations=40):
    """Complete PGD attack pipeline"""
    print("üéØ Starting PGD Attack Generation")

    # Load and prepare data
    data = pd.read_csv(csv_path)
    print(f"‚úì Loaded dataset: {data.shape}")

    # Separate features and labels
    if 'label' in data.columns:
        X = data.drop('label', axis=1).values
        y = data['label'].values
        feature_names = list(data.columns[:-1])
    else:
        X = data.iloc[:, :-1].values
        y = data.iloc[:, -1].values
        feature_names = [f'feature_{i}' for i in range(X.shape[1])]

    # Encode labels
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    y_categorical = to_categorical(y_encoded)

    # Split and scale data
    X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Train model
    model = create_and_train_model(X_train_scaled, y_train, X_test_scaled, y_test)

    # Initialize PGD attacker
    attacker = PGDAttacker(model)

    # Select samples for attack
    if sample_size > len(X_test_scaled):
        sample_size = len(X_test_scaled)

    indices = np.random.choice(len(X_test_scaled), sample_size, replace=False)
    X_attack = X_test_scaled[indices]
    y_attack = y_test[indices]
    y_labels = label_encoder.inverse_transform(np.argmax(y_attack, axis=1))

    # Calculate data range
    data_range = np.max(X_attack) - np.min(X_attack)

    # Create output directory
    output_dir = 'adversarial_csv_pgd'
    os.makedirs(output_dir, exist_ok=True)

    print(f"‚úì Generating PGD attacks for {len(epsilon_percentages)} perturbation levels...")
    print(f"‚úì Using {num_iterations} iterations per attack")

    summary_data = []

    # Generate attacks for each epsilon
    for eps_percent in epsilon_percentages:
        epsilon = (eps_percent / 100.0) * data_range
        alpha = epsilon / 4  # PGD step size
        print(f"\nüî∏ {eps_percent}% perturbation (Œµ={epsilon:.6f}, Œ±={alpha:.6f})")

        # Generate PGD adversarial examples
        x_adv, perturbations = attacker.pgd_attack(
            X_attack, y_attack, epsilon, alpha=alpha, num_iterations=num_iterations
        )

        # Calculate statistics
        predictions_clean = model.predict(X_attack, verbose=0)
        predictions_adv = model.predict(x_adv, verbose=0)

        accuracy_clean = accuracy_score(np.argmax(y_attack, axis=1), np.argmax(predictions_clean, axis=1))
        accuracy_adv = accuracy_score(np.argmax(y_attack, axis=1), np.argmax(predictions_adv, axis=1))
        attack_success_rate = 1 - accuracy_adv

        # Calculate perturbation statistics
        perturbation_norms = np.linalg.norm(perturbations, axis=1)
        avg_perturbation_norm = np.mean(perturbation_norms)

        print(f"   ‚úì Attack success rate: {attack_success_rate:.4f}")
        print(f"   ‚úì Avg perturbation norm: {avg_perturbation_norm:.6f}")

        # Create CSV
        df_adversarial = pd.DataFrame(x_adv, columns=feature_names)
        df_adversarial['label'] = y_labels
        df_adversarial['perturbation_level'] = f'{eps_percent}%'
        df_adversarial['epsilon_value'] = epsilon
        df_adversarial['alpha_value'] = alpha
        df_adversarial['num_iterations'] = num_iterations
        df_adversarial['attack_method'] = 'PGD'
        df_adversarial['random_start'] = True
        df_adversarial['perturbation_norm'] = perturbation_norms

        # Add predictions
        predicted_classes = np.argmax(predictions_adv, axis=1)
        predicted_labels = label_encoder.inverse_transform(predicted_classes)
        df_adversarial['predicted_label'] = predicted_labels
        df_adversarial['prediction_confidence'] = np.max(predictions_adv, axis=1)
        df_adversarial['attack_successful'] = (y_labels != predicted_labels)

        # Calculate attack strength (perturbation efficiency)
        df_adversarial['attack_strength'] = df_adversarial['attack_successful'] / (df_adversarial['perturbation_norm'] + 1e-8)

        # Save CSV
        csv_filename = f"{output_dir}/pgd_adversarial_examples_{eps_percent}percent.csv"
        df_adversarial.to_csv(csv_filename, index=False)
        print(f"   ‚úì Saved: {csv_filename}")

        # Store summary
        summary_data.append({
            'perturbation_level': f'{eps_percent}%',
            'epsilon_value': epsilon,
            'alpha_value': alpha,
            'num_iterations': num_iterations,
            'samples_count': len(x_adv),
            'attack_success_rate': attack_success_rate,
            'avg_perturbation_norm': avg_perturbation_norm,
            'max_perturbation_norm': np.max(perturbation_norms),
            'attack_method': 'PGD'
        })

    # Save summary
    summary_df = pd.DataFrame(summary_data)
    summary_path = f"{output_dir}/pgd_attack_summary.csv"
    summary_df.to_csv(summary_path, index=False)

    print(f"\n‚úÖ PGD Attack Generation Completed!")
    print(f"üìÑ Files created:")
    for eps in epsilon_percentages:
        print(f"   ‚Ä¢ {output_dir}/pgd_adversarial_examples_{eps}percent.csv")
    print(f"   ‚Ä¢ {output_dir}/pgd_attack_summary.csv")

    print(f"\nüìä Summary:")
    print(summary_df.to_string(index=False))

    return summary_df

def compare_attack_methods():
    """Compare PGD with other attack methods"""
    print("\nüîç COMPARING PGD WITH OTHER ATTACKS")
    print("=" * 50)

    attack_dirs = {
        'PGD': 'adversarial_csv_pgd',
        'BIM': 'adversarial_csv_bim',
        'DeepFool': 'adversarial_csv_deepfool',
        'FGSM': 'adversarial_csv'
    }

    comparison_data = []

    for method, directory in attack_dirs.items():
        if method == 'FGSM':
            summary_file = f"{directory}/attack_summary.csv"
        else:
            summary_file = f"{directory}/{method.lower()}_attack_summary.csv"

        try:
            summary = pd.read_csv(summary_file)

            for _, row in summary.iterrows():
                comparison_data.append({
                    'Method': method,
                    'Perturbation': row['perturbation_level'],
                    'Success Rate': f"{row['attack_success_rate']:.4f}",
                    'Avg Norm': f"{row['avg_perturbation_norm']:.6f}"
                })
        except FileNotFoundError:
            print(f"‚ö†Ô∏è  {method} results not found")

    if comparison_data:
        comparison_df = pd.DataFrame(comparison_data)

        # Pivot table for better comparison
        pivot_success = comparison_df.pivot(index='Perturbation', columns='Method', values='Success Rate')

        print("\nüìä Attack Success Rate Comparison:")
        print(pivot_success.to_string())

        print(f"\nüí° PGD Characteristics:")
        print(f"   ‚Ä¢ Stronger than BIM due to random restarts")
        print(f"   ‚Ä¢ Multiple iterations with projection")
        print(f"   ‚Ä¢ Often considered the strongest first-order attack")
        print(f"   ‚Ä¢ Good balance of effectiveness and computational cost")

# Example usage
if __name__ == "__main__":
    # üîπ UPDATE THIS PATH
    CSV_PATH = "kdd_selected_features.csv"

    print("üöÄ PGD ATTACK IMPLEMENTATION")
    print("=" * 50)

    try:
        # Generate PGD attacks and CSV files
        summary = generate_pgd_attacks_and_csv(CSV_PATH, num_iterations=40)

        print(f"\nüéØ Ready for defense testing!")
        print(f"PGD characteristics:")
        print(f"   ‚Ä¢ Random initialization + iterative refinement")
        print(f"   ‚Ä¢ Stronger than FGSM/BIM attacks")
        print(f"   ‚Ä¢ Considered gold standard for adversarial robustness")
        print(f"   ‚Ä¢ Projects perturbations to stay within epsilon ball")

        print(f"\nLoad adversarial examples:")
        print(f"   df = pd.read_csv('adversarial_csv_pgd/pgd_adversarial_examples_10percent.csv')")
        print(f"   X_adv = df[feature_columns].values")
        print(f"   y_true = df['label'].values")

        # Compare with other methods if available
        compare_attack_methods()

    except FileNotFoundError:
        print(f"‚ùå Dataset not found at: {CSV_PATH}")
        print(f"Please update CSV_PATH with your actual file location")
    except Exception as e:
        print(f"‚ùå Error: {e}")