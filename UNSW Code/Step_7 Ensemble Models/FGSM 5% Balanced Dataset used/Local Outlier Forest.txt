import pandas as pd
import pickle
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import numpy as np

# Load data
df = pd.read_csv('FGSM_5percent_kddcup99_minmax.csv')
X = df.drop('label', axis=1) if 'label' in df.columns else df  # Remove target if exists
y = df['label'] if 'label' in df.columns else None

# Scale features (important for LOF)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data if you have labels for evaluation
if y is not None:
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )
else:
    X_train = X_scaled

# Train Local Outlier Factor model
lof_model = LocalOutlierFactor(
    n_neighbors=20,
    contamination=0.1,  # Expected proportion of outliers
    novelty=True  # Enable novelty detection for new data
)

lof_model.fit(X_train)

# Predict anomalies (-1 for outliers, 1 for inliers)
predictions = lof_model.predict(X_train)
anomaly_scores = lof_model.decision_function(X_train)

print(f"Number of outliers detected: {np.sum(predictions == -1)}")
print(f"Percentage of outliers: {(np.sum(predictions == -1) / len(predictions)) * 100:.2f}%")

# Save model and preprocessing objects
model_data = {
    'model': lof_model,
    'scaler': scaler,
    'feature_names': X.columns.tolist()
}

with open('FGSM_5percent_lof_model_kddcup.pkl', 'wb') as f:
    pickle.dump(model_data, f)

print("Model saved as FGSM_5percent_lof_model_kddcup.pkl")